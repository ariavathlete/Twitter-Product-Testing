### Twitter Advertising Campaign
##### Abstract:

Twitter has been noticing an increase in overspend on the platform. In an attempt to reduce the amount of overspend, they decided to create a new product where advertisers pay each time their ad appears in a userâ€™s viewport rather than each time it is clicked on -- presumably these engagements would be received at a lower latency. In order to test the new product, we ran an A/B test. We randomly split the advertisers on the platform. Half of the advertisers remained on the old product and half received the new product. A week later we have some data and want to determine whether or not the experiment was a success.

1. How many campaigns have overspend of greater than 1% of their budget in the control group? In the treatment group? 
2. Was the new product effective at reducing overspend, and was it more or less effective depending on the company size? Put together an analysis describing how the treatment affected overspend. 
3. A product manager on the team is concerned that certain advertisers in the treatment group are entering lower budgets because they are wary of the new product. Provide some evidence to support their suspicions, or show that any differences in budgets are likely due to random fluctuations.

##### Business Goal: 
1. Reduce overspending.
2. Increase Consumers budget.
3. Increase Customer satisfaction.

##### Metrics:
1. Overspending: We want to see that overspending reduced in the treatment group.
2. Budget: We want to see that the average campaign budget increased in the treatment group.

#### Files:
###### Dataset
[dataset.xlsx](/dataset.xlsx)
###### Presentation
[twitter_abtesting.pdf](/twitter_abtesting.pdf)
###### Question 1 & EDAs
[quest_1.ipynb](/quest_1.ipynb)
###### Question 2
[quest_2.ipynb](/quest_2.ipynb)
###### Question 3
[quest_3.ipynb](/quest_3.ipynb)
 
